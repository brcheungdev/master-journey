# My notes
- This folder contains my notes, thoughts and learning summaries during my master's degree study.  
- The main topics include: **Computer Architecture(コンピュータ構成論)**.  
- Instructor: Prof. Shinji Tomita (富田眞治)  

---

# Lecture 11: Memory Systems — Hierarchy, Virtual Memory & Caches  <br/>
内存系统：层次结构、虚拟内存与缓存

Memory hierarchy, locality, virtual memory (paging/segmentation, TLB), page replacement, cache mapping & write policies, multi-level caches, VA→TLB→Cache pipeline, storage devices, Fugaku overview  
内存层次结构、局部性、虚拟内存（分页/分段、TLB）、页面替换、缓存映射与写入策略、多级缓存、VA→TLB→缓存流水线、存储设备、富岳超级计算机概述  

---

## ⚪ Lecture Overview 讲座概览
- Memory performance metrics: **access time / cycle time / latency / bandwidth**  
  内存性能指标：访问时间 / 周期时间 / 延迟 / 带宽  
- Why **memory hierarchy** works: **temporal & spatial locality**, system integration  
  内存层次结构为何有效：时间与空间局部性、系统集成  
- **Virtual memory**: paging & segmentation; **page table / TLB**; page faults  
  虚拟内存：分页与分段；页表 / TLB；页面错误  
- **Replacement policies**: FIFO anomaly, **LRU**, Working Set  
  替换策略：先进先出异常、LRU、工作集  
- **Caches**: block/line, set-associative, directory & data array, write-through vs write-back  
  缓存：块 / 行、组关联、目录与数据阵列、写直达与写回  
- **Multi-level caches** and effective access-time formulas; **split I$ / D$ (Harvard)**  
  多级缓存与有效访问时间公式；分离 I$ / D$（哈佛结构）  
- **VA → TLB → Cache → Memory** access pipeline  
  VA → TLB → 缓存 → 内存的访问流水线  
- Storage landscape: **DRAM / SSD / HDD / RAID / Tape / DVD / BD / USB / Optane**  
  存储层次：DRAM / SSD / HDD / RAID / 磁带 / DVD / BD / USB / Optane  
- **Address space evolution** (IBM/Intel) & **Fugaku** supercomputer notes  
  地址空间演进（IBM / Intel）与富岳超级计算机说明  

---

### 1) Memory Requirements & Performance Metrics  
内存需求与性能指标
- **Access time**: time until data becomes available  
  访问时间：数据可被获取所需的时间  
- **Cycle time**: time until next R/W is possible (≥ access time)  
  周期时间：下次读写可行所需的时间（≥ 访问时间）  
- **Latency**: delay until first data in a burst  
  延迟：第一次传输到数据所需的时间  
- **Bandwidth (throughput)**: bytes or transfers per second (max BW excludes latency)  
  带宽（吞吐量）：每秒传输的字节数（不计延迟）  

---

### 2) Memory Hierarchy (Registers → Caches → DRAM → SSD/HDD → Archive)  
存储层次结构（寄存器 → 缓存 → DRAM → SSD/HDD → 存档）
- **Registers**: O(100 ps), a few dozen entries  
  寄存器：O(100 皮秒)，几十个条目  
- **L1/L2/L3 Caches**: O(100 ps–ns), MB-scale  
  一级 / 二级 / 三级缓存：O(100 皮秒到纳秒)，兆字节规模  
- **Main Memory (DRAM)**  
  主内存（DRAM）  
- **Secondary / Mass Storage**: **SSD/HDD**, Data Warehouse/Archive  
  次级 / 大容量存储：SSD/HDD，数据仓库 / 存档  
- **Portable storage**: **USB**, **DVD/BD**, **Magnetic Tape** (~45 TB, ~1 GB/s)  
  便携存储：USB、DVD/BD、磁带（约 45TB，约 1GB/s）  
- **Goal**: hide main memory **latency** and **capacity** limits by leveraging hierarchy  
  目标：利用层次结构隐藏主存的延迟和容量限制  

**Why effective? 为何有效？**  
1) **Locality of reference**  
   - **Temporal**: recently used will be used again  
     时间局部性：最近使用的数据可能再次使用  
   - **Spatial**: nearby addresses likely accessed soon  
     空间局部性：相邻地址可能会很快被访问  
2) **System integration**: combine diverse technologies to approximate the “ideal” memory  
   系统整合：结合不同技术逼近理想内存  

---

### 3) Virtual Memory — Address Spaces & Methods  
虚拟内存 — 地址空间与方法
- **Paging**: split VA into fixed-size pages, PA into frames; map at run time  
  分页：虚拟地址分割成固定大小页面，物理地址分割成帧，运行时映射  
- **Segmentation**: variable-length segments mapped to contiguous PA; often **combined** with paging  
  分段：可变长度段映射到连续物理地址，常与分页结合  

**Fragmentation**  
- Segmentation may cause **external fragmentation**; compaction can “pack” segments  
  分段可能导致外部碎片，压缩可缓解  

---

### 4) VA→PA Translation — Page Table & TLB  
VA→PA 转换 — 页表与 TLB
- **Page Table**: maps virtual page number (VPN) to physical frame number (PFN)  
  页表：将虚拟页号映射到物理帧号  
- **TLB** caches VPN→PFN pairs; hit → skip page table; miss → consult page table  
  TLB 缓存 VPN→PFN 对；命中则跳过页表，未命中则访问页表  

**Page replacement**  
- **FIFO** (Belady’s anomaly)  
- **LRU** (Least Recently Used)  
- **Working Set** (time-window based)  

---

### 5) Caches — Principles & Organization  
缓存 — 原理与结构
- **Mapping**: direct-mapped, fully-associative, set-associative  
  映射方式：直接映射、全关联、组关联  
- **Replacement**: typically **LRU**  
  替换策略：常用 LRU  
- **Writes**: **write-through** vs **write-back**  
  写策略：写直达 vs 写回  
- **Multi-level caches**: L1/L2/L3 hierarchy  
  多级缓存：L1/L2/L3 层次  

**Effective Access Time (EAT)**  
```c
Single-level: T_C = T_H + β · T_L1
Two-level:   T_C = T_H + β · T_L1 + βγ · T_L2
```

### 6) VA → TLB → Cache → Memory Pipeline
VA→TLB→缓存→内存流水线
1. VA generated by instruction (e.g., LOAD)
2. TLB lookup → PFN
3. Cache lookup → hit/miss
4. Miss → fetch from memory → install block → LRU eviction
5. Write-through vs Write-back policies apply

### 7) Storage Devices & Throughputs
存储设备与带宽
- SSD / HDD / RAID / Tape / DVD / BD / USB / Optane
- Tape ~45 TB, ~1 GB/s; Optane ~10 μs latency

### 8) Address Space Evolution (IBM / Intel)
地址空间演进（IBM / Intel）
- IBM: S/360 (24-bit) → z/Arch (64-bit)
- Intel: 8086 (1 MB) → IA-32 (4 GB) → x86-64 (64-bit)

### 9) Fugaku Supercomputer — Memory & Vector Notes
富岳超级计算机 — 内存与向量计算
- Peak ~414 PFLOPS (2.7 TF/node × 153,600 nodes), power 30–40 MW
- SVE vector extension, HBM high-bandwidth memory
- Node: shared memory; inter-node: Tofu 6-D torus network
- Benchmarks: TOP500, HPCG, HPL-AI, Graph500

---
### Key Points
- Locality + hierarchy hides latency and capacity limits
局部性与层次结构可隐藏延迟与容量限制
- Virtual memory provides large contiguous VA per process; TLB reduces overhead
虚拟内存提供大而连续的地址空间，TLB 减少开销
- Replacement policies (FIFO anomaly, LRU, Working Set) impact performance
替换策略影响性能（FIFO 异常、LRU、工作集）
- Cache design: mapping, block size, write policy, multi-level stacking
缓存设计：映射、块大小、写策略、多级堆叠
- Pipeline VA→TLB→Cache→Memory explains where misses originate
VA→TLB→缓存→内存的流水线解释了未命中来源
