[← Back to Course Directory / 返回课程目录](./README.md#toc) · [Notes Home / 笔记首页](../) · [Repository Home / 仓库首页](../../README.md)

# My notes
- This folder contains my notes, thoughts, and learning summaries during my master's degree study.  
- The main topics include: **Computer Architecture(コンピュータ構成論)**.  
- Instructor: Prof. Shinji Tomita (富田眞治)  

---

# Lecture 11: Memory Systems — Hierarchy, Virtual Memory & Caches  <br/>
内存系统：层次结构、虚拟内存与缓存

Memory hierarchy, locality, virtual memory (paging/segmentation, TLB), page replacement, cache mapping & write policies, multi-level caches, VA→TLB→Cache pipeline, storage devices, Fugaku overview  
内存层次结构、局部性、虚拟内存（分页/分段、TLB）、页面替换、缓存映射与写入策略、多级缓存、VA→TLB→缓存流水线、存储设备、富岳超级计算机概述  

---

## ⚪ Lecture Overview 
- Memory performance metrics: **access time / cycle time / latency / bandwidth**  
  内存性能指标：访问时间 / 周期时间 / 延迟 / 带宽  
- Why **memory hierarchy** works: **temporal & spatial locality**, system integration  
  内存层次结构为何有效：时间与空间局部性、系统整合  
- **Virtual memory**: paging & segmentation; **page table / TLB**; page faults  
  虚拟内存：分页与分段；页表 / TLB；页面错误（缺页）  
- **Replacement policies**: FIFO anomaly, **LRU**, Working Set  
  替换策略：先进先出（Belady 异常）、**LRU**、工作集  
- **Caches**: block/line, set-associative, directory & data array, write-through vs write-back  
  缓存：块 / 行、组相联、目录与数据阵列、写直达 vs 写回  
- **Multi-level caches** and effective access-time formulas; **split I$ / D$ (Harvard)**  
  多级缓存与有效访问时间公式；分离指令/数据缓存（哈佛结构）  
- **VA → TLB → Cache → Memory** access pipeline  
  **VA → TLB → Cache → Memory** 访问流水线  
- Storage landscape: **DRAM / SSD / HDD / RAID / Tape / DVD / BD / USB / Optane**  
  存储层次：**DRAM / SSD / HDD / RAID / 磁带 / DVD / BD / USB / Optane**  
- **Address space evolution** (IBM/Intel) & **Fugaku** supercomputer notes  
  **地址空间演进**（IBM / Intel）与 **富岳** 超级计算机要点  

---

### 1) Memory Requirements & Performance Metrics  
内存需求与性能指标
- **Access time**: time until data becomes available  
  **访问时间**：数据可被获取所需时间  
- **Cycle time**: time until next R/W is possible (≥ access time)  
  **周期时间**：直到下一次读/写可进行所需时间（≥ 访问时间）  
- **Latency**: delay until first data in a burst  
  **延迟**：突发传输中首个数据到达前的等待时间  
- **Bandwidth (throughput)**: bytes or transfers per second (max BW excludes latency)  
  **带宽（吞吐量）**：每秒传输的字节数或事务数（最大带宽不计延迟）  

---

### 2) Memory Hierarchy (Registers → Caches → DRAM → SSD/HDD → Archive)  
存储层次结构（寄存器 → 缓存 → DRAM → SSD/HDD → 存档）
- **Registers**: O(100 ps), a few dozen entries  
  **寄存器**：约 100 皮秒量级，数量几十个  
- **L1/L2/L3 Caches**: O(100 ps–ns), MB-scale  
  **一级/二级/三级缓存**：约 100 皮秒至纳秒，容量以 MB 计  
- **Main Memory (DRAM)**  
  **主内存（DRAM）**  
- **Secondary / Mass Storage**: **SSD/HDD**, Data Warehouse/Archive  
  **次级/海量存储**：**SSD/HDD**，数据仓库/归档  
- **Portable storage**: **USB**, **DVD/BD**, **Magnetic Tape** (~45 TB, ~1 GB/s)  
  **便携存储**：**USB**、**DVD/BD**、**磁带**（约 45 TB，约 1 GB/s）  
- **Goal**: hide main memory **latency** and **capacity** limits by leveraging hierarchy  
  **目标**：利用层次结构隐藏主存的**延迟**与**容量**瓶颈  

**Why effective? 为何有效？**  
1) **Locality of reference**  
   **引用局部性**  
   - **Temporal**: recently used will be used again  
     **时间局部性**：最近使用的数据更可能再次被访问  
   - **Spatial**: nearby addresses likely accessed soon  
     **空间局部性**：相邻地址很快可能被访问  
2) **System integration**: combine diverse technologies to approximate the “ideal” memory  
   **系统整合**：融合不同技术以逼近“理想内存”  

---

### 3) Virtual Memory — Address Spaces & Methods  
虚拟内存 — 地址空间与方法
- **Paging**: split VA into fixed-size pages, PA into frames; map at run time  
  **分页**：虚拟地址划分为固定大小页面，物理地址划分为帧；运行时建立映射  
- **Segmentation**: variable-length segments mapped to contiguous PA; often **combined** with paging  
  **分段**：可变长度的段映射到连续物理地址；常与分页**结合**  

**Fragmentation**  
**碎片问题**  
- Segmentation may cause **external fragmentation**; compaction can “pack” segments  
  **分段**可能造成**外部碎片**；内存压缩可“打包”段以缓解  

---

### 4) VA→PA Translation — Page Table & TLB  
VA→PA 转换 — 页表与 TLB
- **Page Table**: maps virtual page number (VPN) to physical frame number (PFN)  
  **页表**：将虚拟页号（VPN）映射到物理帧号（PFN）  
- **TLB** caches VPN→PFN pairs; hit → skip page table; miss → consult page table  
  **TLB** 缓存 VPN→PFN 对；命中→跳过页表；未命中→访问页表  

**Page replacement**  
**页面置换**  
- **FIFO** (Belady’s anomaly)  
  **先进先出（FIFO）**（Belady 异常）  
- **LRU** (Least Recently Used)  
  **LRU**（最近最少使用）  
- **Working Set** (time-window based)  
  **工作集**（基于时间窗口）  
---

### 5) Caches — Principles & Organization  
缓存 — 原理与结构
- **Mapping**: direct-mapped, fully-associative, set-associative  
  **映射方式**：直接映射、全相联、组相联  
- **Replacement**: typically **LRU**  
  **替换策略**：通常为 **LRU**  
- **Writes**: **write-through** vs **write-back**  
  **写策略**：**写直达** vs **写回**  
- **Multi-level caches**: L1/L2/L3 hierarchy  
  **多级缓存**：L1/L2/L3 层次  

**Effective Access Time (EAT)**  
**有效访问时间（EAT）**
```c
Single-level: T_C = T_H + β · T_L1
Two-level:   T_C = T_H + β · T_L1 + βγ · T_L2
```

### 6) VA → TLB → Cache → Memory Pipeline  
VA → TLB → Cache → Memory 流水线
1. VA generated by instruction (e.g., LOAD)  
   指令生成虚拟地址（如 LOAD）  
2. TLB lookup → PFN  
   查询 TLB 得到 PFN  
3. Cache lookup → hit/miss  
   在缓存中查找 → 命中/未命中  
4. Miss → fetch from memory → install block → LRU eviction  
   未命中 → 从内存取块 → 安装到缓存 → 按 LRU 淘汰旧块  
5. Write-through vs Write-back policies apply  
   应用写直达或写回策略  

### 7) Storage Devices & Throughputs  
存储设备与带宽
- SSD / HDD / RAID / Tape / DVD / BD / USB / Optane  
  SSD / HDD / RAID / 磁带 / DVD / BD / USB / Optane  
- Tape ~45 TB, ~1 GB/s; Optane ~10 μs latency  
  磁带约 45 TB、约 1 GB/s；Optane 延迟约 10 μs  

### 8) Address Space Evolution (IBM / Intel)  
地址空间演进（IBM / Intel）
- IBM: S/360 (24-bit) → z/Arch (64-bit)  
  IBM：S/360（24 位）→ z/Arch（64 位）  
- Intel: 8086 (1 MB) → IA-32 (4 GB) → x86-64 (64-bit)  
  Intel：8086（1 MB）→ IA-32（4 GB）→ x86-64（64 位）  

### 9) Fugaku Supercomputer — Memory & Vector Notes  
富岳超级计算机 — 内存与向量要点
- Peak ~414 PFLOPS (2.7 TF/node × 153,600 nodes), power 30–40 MW  
  峰值约 414 PFLOPS（每节点 2.7 TF × 153,600 节点），功耗 30–40 MW  
- SVE vector extension, HBM high-bandwidth memory  
  SVE 向量扩展，HBM 高带宽内存  
- Node: shared memory; inter-node: Tofu 6-D torus network  
  节点：共享内存；节点间：Tofu 六维环面网络  
- Benchmarks: TOP500, HPCG, HPL-AI, Graph500  
  评测：TOP500、HPCG、HPL-AI、Graph500  

---
### Key Points
- Locality + hierarchy hides latency and capacity limits  
  局部性 + 层次结构可以隐藏延迟与容量限制  
- Virtual memory provides large contiguous VA per process; TLB reduces overhead  
  虚拟内存为每个进程提供大的连续虚拟地址空间；TLB 降低地址转换开销  
- Replacement policies (FIFO anomaly, LRU, Working Set) impact performance  
  替换策略（FIFO 异常、LRU、工作集）显著影响性能  
- Cache design: mapping, block size, write policy, multi-level stacking  
  缓存设计：映射方式、块大小、写入策略与多级堆叠  
- Pipeline VA→TLB→Cache→Memory explains where misses originate  
  VA→TLB→Cache→Memory 的流水线解释了未命中的来源

  <h2></h2>

[← Previous Lecture / 上一章](./Lecture10.md) · [→ Next Lecture / 下一章](./Lecture12.md) · [Notes Home / 笔记首页](../) · [Repository Home / 仓库首页](../../README.md)

